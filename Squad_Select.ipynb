{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data available at : https://github.com/LianHaiMiao/Attentive-Group-Recommendation "
      ],
      "metadata": {
        "id": "1v63JXd1CdBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Exploration**"
      ],
      "metadata": {
        "id": "nO-9ps-FqUhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sp\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "geFhRZc5s3cw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(object):\n",
        "  def __init__(self):\n",
        "    self.data_path='/content/'"
      ],
      "metadata": {
        "id": "Jvb-o7MZsRlS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "r0H9hbAep_gj"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Dataset(object):\n",
        "  def __init__ (self, data_path)  :\n",
        "        \n",
        "        print(\"loading User Train Matrix...\")\n",
        "        self.user_trainMatrix=self.load_rating_file_as_matrix(data_path+\"userRatingTrain.txt\")\n",
        "        print(\"loading Group Train Matrix...\")\n",
        "        self.group_trainMatrix=self.load_rating_file_as_matrix(data_path+\"groupRatingTrain.txt\")\n",
        "        print(\"loading User Test Matrix...\")\n",
        "        self.user_testMatrix=self.load_rating_file_as_matrix(data_path+\"userRatingTest.txt\")\n",
        "        print(\"loading Group Test Matrix...\")\n",
        "        self.group_testMatrix=self.load_rating_file_as_matrix(data_path+\"groupRatingTest.txt\")\n",
        "        \n",
        "        # process negative data\n",
        "        #print(\"loading User Negative into User test Matrix:\")\n",
        "        #self.user_testMatrix=self.load_negative_data(self.user_testMatrix, data_path+\"userRatingNegative.txt\")\n",
        "        \n",
        "        #taken num items as per train data since they are different in test matrices from train matrice item counts\n",
        "        self.num_users, self.num_items = self.user_trainMatrix.shape\n",
        "        self.num_groups=self.group_trainMatrix.shape[0]\n",
        "\n",
        "        #implicit matrices\n",
        "        self.implicit_user_trainMatrix=np.zeros((self.user_trainMatrix.shape))\n",
        "        self.implicit_user_testMatrix=np.zeros((self.user_testMatrix.shape))\n",
        "        self.implicit_group_trainMatrix=np.zeros((self.group_trainMatrix.shape))\n",
        "        self.implicit_group_testMatrix=np.zeros((self.group_testMatrix.shape))\n",
        "\n",
        "        print(\"loading Implicit User Train Matrix...\")\n",
        "        self.implicit_user_trainMatrix[self.user_trainMatrix!=0]=1\n",
        "        print(\"loading Implicit User Test Matrix...\")\n",
        "        self.implicit_user_testMatrix[self.user_testMatrix!=0]=1\n",
        "        print(\"loading Implicit Group Train Matrix...\")\n",
        "        self.implicit_group_trainMatrix[self.group_trainMatrix!=0]=1\n",
        "        print(\"loading Implicit Group Test Matrix...\")\n",
        "        self.implicit_group_testMatrix[self.group_testMatrix!=0]=1\n",
        "\n",
        "        #group-user mapping\n",
        "        print(\"loading Group-User Mapping Data...\")\n",
        "        self.group_user_Dict=self.extract_group_user_data(data_path+\"groupMember.txt\")\n",
        "\n",
        "  def extract_group_user_data(self, filename):\n",
        "        group_user_dict={}\n",
        "        with open(filename, \"r\") as f:\n",
        "            line=f.readline()\n",
        "            while line!=None and line!=\"\":\n",
        "                arr=line.split(\" \")\n",
        "                arr[1] = arr[1].replace(\"\\n\", \"\")\n",
        "                members=arr[1].split(\",\")\n",
        "                if arr[0] not in group_user_dict:\n",
        "                    group_user_dict[int(arr[0])]= [int(x) for x in members]\n",
        "                line=f.readline()\n",
        "        return group_user_dict\n",
        "\n",
        "  def load_rating_file_as_matrix(self, filename):\n",
        "        # Get number of users and items\n",
        "        num_users, num_items = 0, 0\n",
        "        with open(filename, \"r\") as f:\n",
        "            line=f.readline()\n",
        "            while line!=None and line!=\"\":\n",
        "                arr=line.split(\" \")\n",
        "                u,i=int(arr[0]), int(arr[1])\n",
        "                num_users=max(num_users,u)\n",
        "                num_items=max(num_items,i)\n",
        "                line=f.readline()\n",
        "      \n",
        "        mat=np.zeros((num_users+1, num_items+1))\n",
        "        with open(filename, \"r\") as f:\n",
        "            line=f.readline()\n",
        "            while line!=None and line!=\"\":\n",
        "                arr=line.split(\" \")\n",
        "                mat[int(arr[0])-1][int(arr[1])-1]=int(arr[2])\n",
        "                line=f.readline()\n",
        "\n",
        "        return mat\n",
        "\n",
        "  #TBD\n",
        "  def load_negative_data(self, matrixname, filename):\n",
        "        with open(filename, \"r\") as f:\n",
        "            line=f.readline()\n",
        "            while line!=None and line!=\"\":\n",
        "                arr=line.split(\" \")\n",
        "                print(arr)\n",
        "                line=f.readline()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "  config=Config()\n",
        "  dataset=Dataset(config.data_path)\n",
        "  num_users, num_items, num_groups = dataset.num_users, dataset.num_items, dataset.num_groups\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzk5-DDxstV6",
        "outputId": "771541df-0726-440a-98bc-46127852adab"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading User Train Matrix...\n",
            "loading Group Train Matrix...\n",
            "loading User Test Matrix...\n",
            "loading Group Test Matrix...\n",
            "loading Implicit User Train Matrix...\n",
            "loading Implicit User Test Matrix...\n",
            "loading Implicit Group Train Matrix...\n",
            "loading Implicit Group Test Matrix...\n",
            "loading Group-User Mapping Data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Details:**"
      ],
      "metadata": {
        "id": "uy7Bldhn7G4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"num users, num items, num groups=({}, {}, {})\".format(num_users, num_items, num_groups))\n",
        "print()\n",
        "print(\"user_traindata shape={}\".format(dataset.user_trainMatrix.shape))\n",
        "print(\"user_testdata shape={}\".format(dataset.user_testMatrix.shape))\n",
        "print(\"group_traindata shape={}\".format(dataset.group_trainMatrix.shape))\n",
        "print(\"group_testdata shape={}\".format(dataset.group_testMatrix.shape))\n",
        "print()\n",
        "print(\"Implicit user_traindata shape={}\".format( dataset.implicit_user_trainMatrix.shape))\n",
        "print(\"implicit user_testdata shape={}\".format(  dataset.implicit_user_testMatrix.shape))\n",
        "print(\"implicit group_traindata shape={}\".format(dataset.implicit_group_trainMatrix.shape))\n",
        "print(\"implicit group_testdata shape={}\".format( dataset.implicit_group_testMatrix.shape))\n",
        "print()\n",
        "print('Group User Data:')\n",
        "print(dataset.group_user_Dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cp1MRnbt31Y",
        "outputId": "83ec69fd-849a-4836-a32b-d7a08dcead16"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num users, num items, num groups=(602, 7710, 290)\n",
            "\n",
            "user_traindata shape=(602, 7710)\n",
            "user_testdata shape=(602, 7679)\n",
            "group_traindata shape=(290, 7710)\n",
            "group_testdata shape=(290, 7656)\n",
            "\n",
            "Implicit user_traindata shape=(602, 7710)\n",
            "implicit user_testdata shape=(602, 7679)\n",
            "implicit group_traindata shape=(290, 7710)\n",
            "implicit group_testdata shape=(290, 7656)\n",
            "\n",
            "Group User Data:\n",
            "{216: [346, 414], 217: [433, 526], 214: [559, 570], 215: [226, 294], 212: [415, 470], 213: [43, 267, 308], 210: [443, 520], 211: [53, 392], 165: [451, 496], 264: [105, 171], 265: [556, 253, 366], 218: [334, 386], 219: [199, 302], 133: [6, 126], 132: [141, 519], 131: [480, 500], 130: [179, 348], 137: [106, 524], 136: [304, 587], 135: [42, 510], 134: [113, 120], 139: [440, 545], 138: [365, 490], 166: [258, 397], 24: [27, 404], 25: [58, 252], 26: [157, 565, 431], 27: [347, 462], 20: [8, 435], 21: [152, 484], 22: [271, 502], 23: [155, 381], 160: [391, 405], 28: [597, 521], 29: [23, 523], 161: [210, 486], 289: [61, 475], 0: [21, 198], 4: [83, 136], 281: [135, 151], 8: [93, 99], 283: [183, 352], 163: [575, 530], 285: [139, 268], 284: [70, 413], 287: [19, 167, 282, 283], 286: [2, 31], 119: [311, 343], 258: [122, 315], 120: [395, 551], 121: [9, 46], 122: [116, 329], 123: [33, 400], 124: [222, 428], 125: [172, 204], 126: [0, 485], 127: [129, 376], 128: [340, 396], 129: [213, 291], 269: [110, 364], 268: [234, 529], 167: [188, 208], 118: [508, 515], 59: [153, 235], 58: [319, 419], 55: [287, 382], 54: [303, 374], 57: [248, 305], 56: [114, 349], 51: [239, 344], 50: [375, 507], 53: [378, 420], 52: [127, 261], 259: [11, 416], 276: [181, 505], 164: [68, 534], 201: [60, 353, 368], 199: [76, 549], 179: [112, 552], 200: [148, 367], 195: [47, 401], 194: [249, 472], 197: [160, 567, 424, 491], 178: [77, 498], 191: [85, 447], 190: [566, 278], 193: [236, 425], 192: [88, 460], 115: [323, 458], 114: [557, 482], 88: [12, 214], 89: [173, 438], 111: [80, 193], 110: [298, 383], 113: [421, 481], 112: [15, 202], 82: [180, 328], 83: [102, 409], 80: [51, 262], 81: [36, 336], 86: [57, 270], 87: [158, 423], 84: [300, 449], 85: [238, 467], 251: [108, 471], 198: [560, 562], 256: [418, 493], 206: [483, 522], 226: [159, 377], 257: [339, 459], 3: [86, 189], 177: [45, 192], 254: [292, 544], 7: [216, 599], 247: [81, 406], 273: [73, 430], 255: [555, 264], 225: [104, 140], 245: [133, 290], 244: [49, 539], 108: [72, 233], 109: [34, 169], 241: [547, 553], 240: [14, 511], 243: [332, 437], 242: [465, 533], 102: [186, 469], 103: [50, 537], 100: [257, 578], 101: [247, 359], 106: [65, 109], 107: [190, 422], 104: [588, 506], 105: [432, 590], 39: [144, 488], 38: [22, 306], 33: [111, 429], 32: [7, 243], 31: [97, 98, 166], 30: [220, 309], 37: [245, 456], 36: [231, 307], 35: [66, 250], 34: [170, 412], 246: [285, 504], 282: [145, 543], 252: [317, 322], 205: [579, 466], 223: [569, 581], 176: [572, 513], 60: [360, 441], 61: [128, 299], 62: [32, 436], 63: [227, 501], 64: [358, 442], 65: [312, 342], 66: [82, 95], 67: [399, 525], 68: [276, 546], 69: [3, 205, 297], 175: [30, 379], 174: [79, 265], 173: [574, 351], 172: [568, 284], 171: [219, 246], 170: [476, 516], 203: [69, 474], 222: [212, 363], 288: [156, 274], 181: [149, 454], 253: [78, 228], 248: [331, 371], 182: [174, 197], 183: [580, 583], 180: [337, 494], 2: [24, 187], 162: [71, 563], 187: [178, 333], 184: [35, 558], 6: [154, 177], 220: [357, 582], 186: [26, 503], 188: [206, 591], 189: [90, 313, 325], 202: [200, 301], 196: [25, 561, 411], 221: [223, 384], 185: [237, 446], 271: [29, 91], 99: [131, 335], 98: [254, 457], 168: [495, 509], 169: [55, 402], 229: [52, 194], 228: [370, 448], 91: [92, 259], 90: [28, 241], 93: [380, 389], 92: [314, 463], 95: [20, 101], 94: [240, 408], 97: [464, 473], 96: [211, 350], 11: [143, 182], 10: [115, 518], 13: [39, 354, 453], 12: [295, 499], 15: [217, 280], 14: [100, 373], 17: [576, 417], 16: [330, 531], 19: [41, 142], 18: [125, 541], 117: [256, 492], 116: [75, 293], 270: [146, 517], 274: [54, 341, 589], 204: [209, 594], 224: [564, 191], 275: [601, 586], 151: [130, 277], 150: [74, 478], 153: [165, 479], 152: [279, 445], 155: [40, 162], 154: [107, 361], 157: [118, 403], 156: [318, 372], 159: [119, 123], 158: [310, 452, 540], 277: [224, 514], 234: [320, 487], 238: [134, 455], 239: [362, 585], 227: [577, 345], 279: [96, 461], 207: [201, 571], 235: [48, 215], 236: [439, 584], 237: [1, 260], 230: [573, 321], 231: [4, 132, 444, 593], 232: [497, 527], 233: [13, 369], 280: [161, 164, 185], 48: [117, 218], 49: [16, 17], 46: [67, 326], 47: [168, 288], 44: [269, 398], 45: [221, 356], 42: [281, 286], 43: [554, 230], 40: [385, 410], 41: [316, 450], 1: [427, 548], 5: [5, 489], 9: [273, 394], 272: [44, 64, 87, 324], 146: [38, 84], 147: [592, 542], 144: [595, 251], 145: [176, 598, 528], 142: [94, 338], 143: [18, 147], 140: [175, 272], 141: [138, 150], 209: [242, 407], 208: [266, 387], 148: [63, 89], 149: [103, 550], 77: [512, 532], 76: [196, 296], 75: [225, 255], 74: [62, 289], 73: [203, 538], 72: [184, 434], 71: [56, 275], 70: [37, 327], 278: [121, 263, 390], 79: [195, 393], 78: [163, 229], 263: [244, 536], 249: [137, 426], 262: [207, 468], 261: [232, 355], 250: [124, 388], 260: [600, 596], 267: [59, 535], 266: [10, 477]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE: Need to check :**\n",
        "\n",
        "\n",
        "\n",
        "1.   Why is test data's item counts different from train data's\n",
        "2.   Plan how to incorporate and make use of negative data wrt to each item and each user/group\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KBl1VJdZDIPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module Function Scripts**"
      ],
      "metadata": {
        "id": "1MUCmLUkCv7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gartrell, M., Xing, X., Lv, Q., Beach, A., Han, R., Mishra, S., & Seada, K. (2010, November). Enhancing group recommendation by incorporating social relationship interactions. In Proceedings of the 16th ACM international conference on Supporting group work (pp. 97-106).**"
      ],
      "metadata": {
        "id": "wTz-Y_X6QwIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Social Relationship"
      ],
      "metadata": {
        "id": "uIcPDG3JQXmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_in_group=np.zeros(num_groups)\n",
        "\n",
        "for group_id in dataset.group_user_Dict:\n",
        "  group_members= dataset.group_user_Dict[group_id]\n",
        "  sum_of_weight_similarities=0\n",
        "  \n",
        "  \n",
        "  for i in range(len(group_members)):\n",
        "    for j in range(i+1,len(group_members)):\n",
        "      user1=group_members[i]\n",
        "      user2=group_members[j]\n",
        "      if user1 != user2:\n",
        "        w_ij=0\n",
        "        user1_items=np.nonzero(dataset.user_trainMatrix[user1])[0]\n",
        "        user2_items=np.nonzero(dataset.user_trainMatrix[user2])[0]\n",
        "        common_items = set(user1_items).intersection(user2_items)\n",
        "        num_common_items = len(common_items)\n",
        "        total_items = set(user1_items).union(user2_items)\n",
        "        num_total_items = len(total_items)\n",
        "\n",
        "        w_ij=num_common_items/num_total_items\n",
        "        sum_of_weight_similarities+=w_ij\n",
        "  similarity_in_group[group_id]=(2*sum_of_weight_similarities)/(len(group_members)*(len(group_members)-1))\n",
        "\n",
        "#print(similarity_in_group)   "
      ],
      "metadata": {
        "id": "xSXj6tSkPu9l"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "social_descriptor_groupwise=np.zeros(num_groups)\n",
        "sorted_values = sorted(similarity_in_group)\n",
        "\n",
        "# Compute the statistical thresholds for each category (since we dont have very strong similarities in any group)\n",
        "q1 = sorted_values[int(len(sorted_values) * 0.2)]\n",
        "q2 = sorted_values[int(len(sorted_values) * 0.4)]\n",
        "q3 = sorted_values[int(len(sorted_values) * 0.6)]\n",
        "q4 = sorted_values[int(len(sorted_values) * 0.8)]\n",
        "\n",
        "print(q1,\",\",q2,\",\",q3,\",\",q4)\n",
        "\n",
        "for i in range(num_groups):\n",
        "        if similarity_in_group[i] <= q1:\n",
        "            social_descriptor_groupwise[i]=0\n",
        "        elif similarity_in_group[i] <= q2:\n",
        "            social_descriptor_groupwise[i]=1\n",
        "        elif similarity_in_group[i] <= q3:\n",
        "            social_descriptor_groupwise[i]=2\n",
        "        elif similarity_in_group[i] <= q4:\n",
        "            social_descriptor_groupwise[i]=3\n",
        "        else:\n",
        "            social_descriptor_groupwise[i]=4\n",
        "    \n",
        "print(social_descriptor_groupwise)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQXJT5QGpINE",
        "outputId": "c347b640-70c5-4a70-b42e-53ec4299011d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04296875 , 0.081145584725537 , 0.11666666666666667 , 0.1608695652173913\n",
            "[0. 0. 2. 2. 0. 4. 4. 0. 2. 3. 4. 4. 3. 2. 4. 3. 3. 0. 4. 4. 1. 4. 3. 3.\n",
            " 4. 3. 4. 4. 0. 1. 2. 3. 4. 4. 4. 4. 2. 2. 1. 3. 1. 0. 3. 0. 4. 0. 2. 4.\n",
            " 4. 3. 4. 0. 1. 2. 3. 4. 4. 0. 2. 0. 3. 4. 2. 1. 0. 4. 1. 0. 1. 4. 3. 2.\n",
            " 4. 1. 1. 1. 4. 1. 4. 3. 2. 2. 1. 2. 3. 1. 3. 0. 4. 0. 0. 1. 2. 0. 3. 1.\n",
            " 0. 0. 0. 2. 2. 3. 0. 3. 1. 0. 1. 2. 2. 4. 1. 0. 3. 3. 0. 2. 0. 0. 1. 2.\n",
            " 4. 0. 3. 1. 0. 2. 2. 0. 4. 4. 3. 1. 1. 3. 3. 0. 2. 3. 1. 4. 1. 2. 2. 1.\n",
            " 1. 1. 3. 0. 2. 3. 4. 3. 0. 2. 0. 2. 1. 1. 3. 1. 0. 1. 1. 3. 0. 2. 4. 1.\n",
            " 4. 3. 0. 4. 0. 3. 1. 1. 0. 4. 0. 0. 1. 0. 3. 1. 0. 4. 2. 1. 2. 3. 3. 0.\n",
            " 1. 2. 3. 2. 1. 2. 3. 2. 3. 1. 0. 1. 2. 2. 3. 4. 0. 4. 4. 3. 3. 2. 0. 4.\n",
            " 0. 2. 1. 3. 4. 1. 1. 0. 3. 4. 2. 1. 4. 0. 2. 2. 4. 0. 0. 1. 2. 0. 2. 0.\n",
            " 2. 3. 1. 4. 3. 0. 2. 0. 3. 2. 4. 0. 2. 4. 1. 2. 3. 3. 3. 3. 1. 3. 2. 4.\n",
            " 1. 1. 4. 0. 4. 4. 4. 4. 3. 2. 3. 1. 2. 3. 1. 2. 4. 3. 0. 1. 1. 1. 2. 3.\n",
            " 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Expertise descriptor"
      ],
      "metadata": {
        "id": "QBt8QboyQanG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Dissimilarity descriptors"
      ],
      "metadata": {
        "id": "ba_qjLEvQdAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Heuristic group concensus function"
      ],
      "metadata": {
        "id": "kex61McsQgEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rank top k"
      ],
      "metadata": {
        "id": "ooWbulNeQjfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Permuted Pipeline creation**"
      ],
      "metadata": {
        "id": "OrYXaHcRC1hG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "8LEi50QnC7-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analysis**"
      ],
      "metadata": {
        "id": "h_ADskKkC_OB"
      }
    }
  ]
}